{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dd51190",
   "metadata": {},
   "source": [
    "## Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894ad35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install chromadb\n",
    "%pip install pypdf\n",
    "%pip install langchain\n",
    "%pip install sentence-transformers\n",
    "\n",
    "import chromadb\n",
    "import json\n",
    "import pypdf\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d30303",
   "metadata": {},
   "source": [
    "## Extract text from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad648cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \n",
    "    reader = pypdf.PdfReader(pdf_path)\n",
    "    \n",
    "    text = \"\"\n",
    "    \n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d16ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_extraction_results = extract_text_from_pdf([ENTER_PATH_TO_PDF])\n",
    "\n",
    "print(pdf_extraction_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9a3166",
   "metadata": {},
   "source": [
    "## Chunk extracted text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text, chunk_size=1000, chunk_overlap=50):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712c4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_ = split_text_into_chunks(pdf_extraction_results)\n",
    "\n",
    "print(chunks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b2cef3",
   "metadata": {},
   "source": [
    "## Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182ca764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(texts, model_name='all-MiniLM-L6-v2'):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    embeddings = model.encode(texts).tolist()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b614c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_ = generate_embeddings(chunks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52999d3",
   "metadata": {},
   "source": [
    "## Add extracted chunks with embeddings to vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea69ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.HttpClient(host='localhost', port=8000)\n",
    "\n",
    "def populate_chroma_db(chunks, embeddings, pdf_name=\"my_document\"):\n",
    "    \n",
    "    collection_name = f\"{pdf_name}_collection\"\n",
    "\n",
    "    # Delete existing collection if it exists to ensure a clean start\n",
    "    try:\n",
    "        chroma_client.delete_collection(name=collection_name)\n",
    "    except:\n",
    "        pass # Collection might not exist\n",
    "        \n",
    "    collection = chroma_client.create_collection(name=collection_name, get_or_create=True)\n",
    "\n",
    "    ids = [f\"{pdf_name}_chunk_{i}\" for i in range(len(chunks))]\n",
    "    metadatas = [{\"source\": pdf_name, \"chunk_index\": i} for i in range(len(chunks))]\n",
    "\n",
    "    collection.add(\n",
    "        documents=chunks,\n",
    "        embeddings=embeddings,\n",
    "        metadatas=metadatas,\n",
    "        ids=ids\n",
    "    )\n",
    "    print(f\"ChromaDB collection '{collection_name}' populated successfully.\")\n",
    "    \n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07e5727c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB collection 'my_document_collection' populated successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Collection(name=my_document_collection)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "populate_chroma_db(chunks_, embeddings_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1677e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(name=\"my_document_collection\", get_or_create=True)\n",
    "\n",
    "results = collection.query(\n",
    "    query_texts=[\"USRHDLR\"], # Chroma will embed this for you\n",
    "    n_results=10\n",
    ")\n",
    "\n",
    "json_results = json.dumps(results, indent=2)\n",
    "\n",
    "print(json_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox_vector_database",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
